{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.columns)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.fillna('', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Locations: ', np.unique(train['location'].to_numpy()), '\\n')\nprint('Keywords: ', np.unique(train['keyword'].to_numpy()), '\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_lenghts = [len(text) for text in train['text']]\nprint('max len: ', max(text_lenghts))\nplt.hist(text_lenghts, bins = int(max(text_lenghts)/2))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, target_count = np.unique(train['target'].to_numpy(), return_counts=True)\ntarget_count/len(train['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = int(len(train['text'])*0.8)\n\nX_train, X_valid = train['text'][:split], train['text'][split:]\ny_train, y_valid = train['target'][:split], train['target'][split:]\n\nX_test = test['text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, target_count = np.unique(y_train.to_numpy(), return_counts=True)\ntarget_count/len(y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(X_batch):\n    #remove urls\n    X_batch = tf.strings.regex_replace(X_batch, \"(http|https)?:\\/\\/(\\S+)\", \"\")\n    \n    X_batch = tf.strings.regex_replace(X_batch, \"[^a-zA-Z0-9,.!?#:']\", \" \")\n    \n    # replace sequence of punctuations with single character\n    X_batch = tf.strings.regex_replace(X_batch, r\"(([.?#@+]){1,})\", r\"\\2\")\n    \n    # creating a space between a word and the punctuation\n    X_batch = tf.strings.regex_replace(X_batch, r\"([?.!,])\", r\" \\1 \")\n    X_batch = tf.strings.regex_replace(X_batch, r'[\" \"]+', \" \")\n    \n    #lowercase\n    X_batch = tf.strings.lower(X_batch)\n    \n    X_batch = '<start> ' + X_batch + ' <end>'\n    X_batch = tf.strings.split(X_batch)\n    \n    return X_batch.to_tensor(default_value=b\"<pad>\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_encode(data,maximum_length) :\n  input_ids = []\n  attention_masks = []\n  \n\n  for i in range(len(data.text)):\n      encoded = tokenizer.encode_plus(\n        \n        data.text[i],\n        add_special_tokens=True,\n        max_length=maximum_length,\n        pad_to_max_length=True,\n        \n        return_attention_mask=True,\n        \n      )\n      \n      input_ids.append(encoded['input_ids'])\n      attention_masks.append(encoded['attention_mask'])\n  return np.array(input_ids),np.array(attention_masks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_ids,train_attention_masks = bert_encode(train,60)\ntest_input_ids,test_attention_masks = bert_encode(test,60)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel\nbert_model = TFBertModel.from_pretrained('bert-large-uncased')\n\nfrom tensorflow.keras.optimizers import Adam\ndef create_model(bert_model):\n  input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n  attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n  \n  output = bert_model([input_ids,attention_masks])\n  output = output[1]\n  output = tf.keras.layers.Dense(32,activation='relu')(output)\n  output = tf.keras.layers.Dropout(0.2)(output)\n\n  output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n  model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n  model.compile(Adam(lr=6e-6), loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(bert_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([train_input_ids,train_attention_masks],train.target,validation_split=0.2, epochs=2,batch_size=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.rint(pred).astype(np.int16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['target'] = result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}